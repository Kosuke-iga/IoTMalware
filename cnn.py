import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import re
import keras
from keras.preprocessing.image import load_img, img_to_array
from keras.models import Sequential, load_model
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.layers.core import Activation, Flatten, Dense, Dropout
from keras.optimizers import Adam, Adagrad, RMSprop, SGD
from keras.utils.np_utils import to_categorical
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard
from keras.datasets import cifar10

'''
setting
'''
BATCH_SIZE = 32
EPOCHS = 5000
LEARNING_RATE = 0.0001
num_classes =2
x_train = []
y_train = []
x_test = []
y_test = []

#input GSI to CNN

'''
model
'''
model = Sequential()

model.add(Conv2D(
    32, # フィルター数（出力される特徴マップのチャネル）
    kernel_size = 3, # フィルターサイズ
    padding = "same", # 入出力サイズが同じ
    activation = "relu", # 活性化関数
    input_shape = (64, 64, 1) # 入力サイズ
))
# 各特徴マップのチャネルは変わらず、サイズが1/2
model.add(MaxPooling2D(pool_size = (2, 2)))
model.add(Conv2D(
    72,
    kernel_size = 3,
    padding = "same", 
    activation = "relu"
))
model.add(MaxPooling2D(pool_size = (2, 2)))
# 全結合層（fully-connected layers）につなげるため、
# マトリックスデータ（多次元配列）である特徴マップを多次元ベクトルに変換（平坦化）
model.add(Flatten())
# サイズ512のベクトル（256次元ベクトル）を出力
model.add(Dense(256, activation = "relu"))
model.add(Dropout(0.5))
# クラス数のベクトルを出力
model.add(Dense(num_classes))
model.add(Activation("softmax"))

optimizer = Adam(lr = LEARNING_RATE)
model.compile(
    optimizer = optimizer,
    loss = "categorical_crossentropy",
    metrics = ["accuracy"]
)

model.summary()

'''
learning
'''
# 学習は、scrkit-learnと同様fitで記述できる
history = model.fit(x_train, y_train,
 batch_size=BATCH_SIZE,
 epochs=EPOCHS,
 verbose=1,
 validation_data=(x_test, y_test))

'''
test
'''
# 評価はevaluateで行う
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])